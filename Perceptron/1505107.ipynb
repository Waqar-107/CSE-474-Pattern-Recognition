{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron algorithm and its variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Define library and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "number_of_features = 0\n",
    "number_of_classes = 0\n",
    "dataset_size = 0\n",
    "\n",
    "seed_val = 107\n",
    "max_itr = 1000\n",
    "\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a class that stands for a class. It has a name and an array to hold the feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object:\n",
    "    def __init__(self, class_name):\n",
    "        self.class_name = class_name\n",
    "        self.features = []\n",
    "\n",
    "\n",
    "Object_Dictionary = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(train_file):\n",
    "    global number_of_features, number_of_classes, dataset_size, Object_Dictionary\n",
    "\n",
    "    f = open(train_file, \"r\")\n",
    "    lines = f.readlines()\n",
    "\n",
    "    number_of_features, number_of_classes, dataset_size = map(int, lines[0].rstrip().split())\n",
    "\n",
    "    for i in range(dataset_size):\n",
    "        data = lines[i + 1].rstrip().split()\n",
    "        class_name = int(data[number_of_features])\n",
    "\n",
    "        if class_name not in Object_Dictionary:\n",
    "            Object_Dictionary[class_name] = Object(class_name)\n",
    "\n",
    "        Object_Dictionary[class_name].features.append(np.array(data[: number_of_features], dtype=float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic perceptron algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.1\n",
    "        self.w = np.random.uniform(-1, 1, number_of_features + 1)\n",
    "        \n",
    "    \n",
    "    # train the model\n",
    "    def train_model(self):\n",
    "        for itr in range(max_itr):\n",
    "            misclassified = []\n",
    "\n",
    "            for key in Object_Dictionary.keys():\n",
    "                for i in range(len(Object_Dictionary[key].features)):\n",
    "                    x = Object_Dictionary[key].features[i]\n",
    "                    x = np.append(x, 1)\n",
    "                    x = np.array(x)\n",
    "\n",
    "                    val = np.dot(self.w, x)\n",
    "\n",
    "                    # actually omega1, classified as omega2\n",
    "                    if key == 1 and val < 0:\n",
    "                        misclassified.append(x * -1)\n",
    "\n",
    "                    # actually omega2, classified as omega1\n",
    "                    elif key == 2 and val > 0:\n",
    "                        misclassified.append(x)\n",
    "\n",
    "            if len(misclassified) == 0:\n",
    "                print(\"training done in\", itr, \"th iteration\")\n",
    "                break\n",
    "\n",
    "            summation = np.zeros(number_of_features + 1)\n",
    "            for i in range(len(misclassified)):\n",
    "                summation += misclassified[i]\n",
    "\n",
    "            summation = self.learning_rate * summation\n",
    "            self.w = self.w - summation\n",
    "            \n",
    "    \n",
    "    # test the model\n",
    "    def test_model(self, test_file):\n",
    "        correctly_detected = 0\n",
    "        \n",
    "        result_output = open(\"results.txt\", \"w\")\n",
    "        result_output.write(\"Perceptron Alogrithm:\\n\\n\")\n",
    "        \n",
    "        f = open(test_file, \"r\")\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for i in range(dataset_size):\n",
    "            data = list(map(float, lines[i].rstrip().split()))\n",
    "\n",
    "            actual_class = int(data[number_of_features])\n",
    "            data[number_of_features] = 1\n",
    "            x = np.array(data)\n",
    "\n",
    "            prod = np.dot(self.w, x)\n",
    "            if prod >= 0:\n",
    "                predicted_class = 1\n",
    "            else:\n",
    "                predicted_class = 2\n",
    "\n",
    "            if predicted_class == actual_class:\n",
    "                correctly_detected += 1\n",
    "            else:\n",
    "                s = \"Sample no: \" + str(i + 1) + \". \"\n",
    "                s += \"Features: \" + str(data[:number_of_features]) + \". \"\n",
    "                s += \"Actual class: \" + str(actual_class) + \". \"\n",
    "                s += \"Predicted class: \" + str(predicted_class) + \"\\n\"\n",
    "                result_output.write(s)\n",
    "\n",
    "        accuracy = (correctly_detected / dataset_size) * 100\n",
    "        print(\"accuracy of basic perceptron algorithm:\", accuracy, \"%\")\n",
    "        \n",
    "        # free the dictionary\n",
    "        Object_Dictionary.clear()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pocket algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pocket_Perceptron:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.1\n",
    "        self.w = np.random.uniform(-1, 1, number_of_features + 1)\n",
    "        self.ws = self.w\n",
    "        self.hs = 0\n",
    "        \n",
    "    \n",
    "    # train the model\n",
    "    def train_model(self):\n",
    "        for itr in range(max_itr):\n",
    "            misclassified = []\n",
    "\n",
    "            for key in Object_Dictionary.keys():\n",
    "                for i in range(len(Object_Dictionary[key].features)):\n",
    "                    x = Object_Dictionary[key].features[i]\n",
    "                    x = np.append(x, 1)\n",
    "                    x = np.array(x)\n",
    "\n",
    "                    val = np.dot(self.w, x)\n",
    "\n",
    "                    # actually omega1, classified as omega2\n",
    "                    if key == 1 and val < 0:\n",
    "                        misclassified.append(x * -1)\n",
    "\n",
    "                    # actually omega2, classified as omega1\n",
    "                    elif key == 2 and val > 0:\n",
    "                        misclassified.append(x)\n",
    "            \n",
    "            # w gives less misclassified so update\n",
    "            if self.hs < dataset_size - len(misclassified):\n",
    "                self.hs = dataset_size - len(misclassified)\n",
    "                self.ws = self.w\n",
    "            \n",
    "            if len(misclassified) == 0:\n",
    "                print(\"training done in\", itr, \"th iteration\")\n",
    "                break\n",
    "\n",
    "            summation = np.zeros(number_of_features + 1)\n",
    "            for i in range(len(misclassified)):\n",
    "                summation += misclassified[i]\n",
    "\n",
    "            summation = self.learning_rate * summation\n",
    "            self.w = self.w - summation\n",
    "            \n",
    "    \n",
    "    # test the model\n",
    "    def test_model(self, test_file):\n",
    "        correctly_detected = 0\n",
    "        \n",
    "        result_output = open(\"results.txt\", \"w\")\n",
    "        result_output.write(\"Perceptron Alogrithm:\\n\\n\")\n",
    "        \n",
    "        f = open(test_file, \"r\")\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for i in range(dataset_size):\n",
    "            data = list(map(float, lines[i].rstrip().split()))\n",
    "\n",
    "            actual_class = int(data[number_of_features])\n",
    "            data[number_of_features] = 1\n",
    "            x = np.array(data)\n",
    "\n",
    "            prod = np.dot(self.ws, x)\n",
    "            if prod >= 0:\n",
    "                predicted_class = 1\n",
    "            else:\n",
    "                predicted_class = 2\n",
    "\n",
    "            if predicted_class == actual_class:\n",
    "                correctly_detected += 1\n",
    "            else:\n",
    "                s = \"Sample no: \" + str(i + 1) + \". \"\n",
    "                s += \"Features: \" + str(data[:number_of_features]) + \". \"\n",
    "                s += \"Actual class: \" + str(actual_class) + \". \"\n",
    "                s += \"Predicted class: \" + str(predicted_class) + \"\\n\"\n",
    "                result_output.write(s)\n",
    "\n",
    "        accuracy = (correctly_detected / dataset_size) * 100\n",
    "        print(\"accuracy of basic perceptron algorithm:\", accuracy, \"%\")\n",
    "        \n",
    "        # free the dictionary\n",
    "        Object_Dictionary.clear()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of basic perceptron algorithm: 97.5 %\n"
     ]
    }
   ],
   "source": [
    "test_file_1 = \"./dataset/testLinearlySeparable.txt\"\n",
    "train_file_1 = \"./dataset/trainLinearlySeparable.txt\"\n",
    "\n",
    "test_file_2 = \"./dataset/testLinearlyNonSeparable.txt\"\n",
    "train_file_2 = \"./dataset/trainLinearlyNonSeparable.txt\"\n",
    "\n",
    "read_dataset(train_file_2)\n",
    "p = Perceptron()\n",
    "p.train_model()\n",
    "p.test_model(test_file_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run pocket algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of basic perceptron algorithm: 97.75 %\n"
     ]
    }
   ],
   "source": [
    "test_file_1 = \"./dataset/testLinearlySeparable.txt\"\n",
    "train_file_1 = \"./dataset/trainLinearlySeparable.txt\"\n",
    "\n",
    "test_file_2 = \"./dataset/testLinearlyNonSeparable.txt\"\n",
    "train_file_2 = \"./dataset/trainLinearlyNonSeparable.txt\"\n",
    "\n",
    "read_dataset(train_file_2)\n",
    "p = Pocket_Perceptron()\n",
    "p.train_model()\n",
    "p.test_model(test_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
