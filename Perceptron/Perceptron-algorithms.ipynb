{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1505107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron algorithm and its variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Define library and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "number_of_features = 0\n",
    "number_of_classes = 0\n",
    "dataset_size = 0\n",
    "\n",
    "dataset = []\n",
    "class_names = []\n",
    "\n",
    "max_itr = 1000\n",
    "seed_val = 107\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(train_file):\n",
    "    global number_of_features, number_of_classes, dataset_size, dataset, class_names\n",
    "\n",
    "    f = open(train_file, \"r\")\n",
    "    lines = f.readlines()\n",
    "\n",
    "    number_of_features, number_of_classes, dataset_size = map(int, lines[0].rstrip().split())\n",
    "\n",
    "    for i in range(dataset_size):\n",
    "        data = lines[i + 1].rstrip().split()\n",
    "        dataset.append(np.array(data[: number_of_features], dtype=float))\n",
    "        class_names.append(int(data[number_of_features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic perceptron algorithm\n",
    "\n",
    "1. initialize weight vector w(number of features + 1) randomly and fix a learning rate.\n",
    "2. fix a iteration number to avoid inifinite loop in case the graph does not converge.\n",
    "3. train the model\n",
    "  * for itr number of times, do-\n",
    "  * define misclassified array\n",
    "  * for all the feature vectors in dataset,\n",
    "  * append 1 with the feature vector to make its size equal to number of features + 1\n",
    "  * determine the dot product\n",
    "  * if the product is negative and class is omega 1 then delx will -1, insert in misclassified array (delx * feature vector)\n",
    "  * else if the product is prositive or zero and class is omega 2, then delx will be -1, insert in misclassifies array (delx * feature vector)\n",
    "  * if the misclassified array is empty then break, training is done\n",
    "  * else update w = w - learning rate * summation(misclassified\n",
    "4. test the model.\n",
    "5. output the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self):\n",
    "        self.w = np.random.uniform(-1, 1, number_of_features + 1)\n",
    "        self.learning_rate = 0.1\n",
    "\n",
    "    def train_model(self):\n",
    "        global dataset, dataset_size, class_names, max_itr\n",
    "\n",
    "        for itr in range(max_itr):\n",
    "            misclassified = []\n",
    "            for i in range(dataset_size):\n",
    "                x = np.array(dataset[i])\n",
    "                x = np.append(x, 1)\n",
    "                actual_class = class_names[i]\n",
    "\n",
    "                prod = np.dot(self.w, x)\n",
    "\n",
    "                if actual_class == 1 and prod < 0:\n",
    "                    misclassified.append(x * -1)\n",
    "                elif actual_class == 2 and prod >= 0:\n",
    "                    misclassified.append(x)\n",
    "\n",
    "            # all got classified\n",
    "            if len(misclassified) == 0:\n",
    "                sys.stdout.write(\"training done at \" + str(itr + 1) + \"th iteration\\n\")\n",
    "                sys.stdout.write(\"w: \" + str(self.w) + \"\\n\")\n",
    "                break\n",
    "\n",
    "            # update w\n",
    "            summation = sum(misclassified)\n",
    "            self.w = self.w - self.learning_rate * summation\n",
    "\n",
    "    def test_model(self, test_file):\n",
    "        global class_names\n",
    "\n",
    "        correctly_classified = 0\n",
    "        results = open(\"results.txt\", \"w\")\n",
    "        results.write(\"Basic Perceptron Algorithm\\n\\n\")\n",
    "\n",
    "        f = open(test_file, \"r\")\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for i in range(len(lines)):\n",
    "            data = list(map(float, lines[i].rstrip().split()))\n",
    "            actual_class = int(data[number_of_features])\n",
    "            data[number_of_features] = 1\n",
    "            data = np.array(data)\n",
    "\n",
    "            prod = np.dot(self.w, data)\n",
    "\n",
    "            if prod > 0:\n",
    "                predicted_class = 1\n",
    "            else:\n",
    "                predicted_class = 2\n",
    "\n",
    "            if actual_class == predicted_class:\n",
    "                correctly_classified += 1\n",
    "            else:\n",
    "                results.write(\"sample no.: \" + str(i + 1) + \". feature value: \" + str(\n",
    "                    data[:number_of_features]) + \". actual class: \" + str(actual_class) + \". predicted class: \" + str(\n",
    "                    predicted_class) + \"\\n\")\n",
    "\n",
    "        accuracy = (correctly_classified / len(lines)) * 100\n",
    "        sys.stdout.write(\"Correctly classified: \" + str(correctly_classified) + \"\\n\")\n",
    "        sys.stdout.write(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "        results.write(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward and Punishment\n",
    "1. initialize weight vector w(number of features + 1) to 0 and fix a learning rate.\n",
    "2. fix a iteration number to avoid inifinite loop in case the graph does not converge.\n",
    "3. train the model\n",
    "  * for itr number of times, do-\n",
    "  * for all the feature vectors in dataset,\n",
    "  * append 1 with the feature vector to make its size equal to number of features + 1\n",
    "  * determine the dot product\n",
    "  * if class is omega1 and misclassified, w = w + learning_rate * x\n",
    "  * if class is omega2 and misclassified, w = w - learning_rate * x\n",
    "  * else keep w as it is\n",
    "  * if w does not change for all the dataset then we are done.\n",
    "4. test the model.\n",
    "5. output the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reward_and_Punishment:\n",
    "    def __init__(self):\n",
    "        self.w = np.zeros(number_of_features + 1)\n",
    "        self.learning_rate = 0.1\n",
    "\n",
    "    def train_model(self):\n",
    "        global dataset, classname\n",
    "\n",
    "        for itr in range(max_itr):\n",
    "            flag = True\n",
    "            for i in range(dataset_size):\n",
    "                x = dataset[i]\n",
    "                actual_class = classname[i]\n",
    "                x[number_of_features] = 1.0\n",
    "\n",
    "                val = np.dot(self.w, x)\n",
    "\n",
    "                # actually omega1, classified as omega2\n",
    "                if actual_class == 1 and val <= 0.0:\n",
    "                    self.w = self.w + self.learning_rate * x\n",
    "                    flag = False\n",
    "\n",
    "                # actually omega2, classified as omega1\n",
    "                elif actual_class == 2 and val >= 0.0:\n",
    "                    self.w = self.w - self.learning_rate * x\n",
    "                    flag = False\n",
    "\n",
    "            if flag:\n",
    "                print(\"stopping at\", itr, \"th iteration\")\n",
    "                print(\"weight vector\", self.w)\n",
    "                break\n",
    "\n",
    "    def test_model(self, test_file):\n",
    "        correctly_classified = 0\n",
    "\n",
    "        results = open(\"./dataset/results.txt\", \"w\")\n",
    "        results.write(\"Reward and Punishment\\n\\n\")\n",
    "\n",
    "        f = open(test_file, \"r\")\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for i in range(len(lines)):\n",
    "            data = list(map(float, lines[i].rstrip().split()))\n",
    "\n",
    "            actual_class = int(data[number_of_features])\n",
    "            data[number_of_features] = 1\n",
    "            x = np.array(data)\n",
    "\n",
    "            prod = np.dot(self.w, x)\n",
    "            if prod >= 0:\n",
    "                predicted_class = 1\n",
    "            else:\n",
    "                predicted_class = 2\n",
    "\n",
    "            if predicted_class == actual_class:\n",
    "                correctly_classified += 1\n",
    "            else:\n",
    "                results.write(\"sample no.: \" + str(i + 1) + \". feature value: \" + str(\n",
    "                    data[:number_of_features]) + \". actual class: \" + str(actual_class) + \". predicted class: \" + str(\n",
    "                    predicted_class) + \"\\n\")\n",
    "\n",
    "        accuracy = (correctly_classified / len(lines)) * 100\n",
    "        sys.stdout.write(\"Correctly classified: \" + str(correctly_classified) + \"\\n\")\n",
    "        sys.stdout.write(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "        results.write(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pocket algorithm\n",
    "\n",
    "1. initialize weight vector w(number of features + 1) randomly and fix a learning rate.\n",
    "2. initialize ws = w and hs = 0.\n",
    "2. fix a iteration number to avoid inifinite loop in case the graph does not converge.\n",
    "3. train the model\n",
    "  * for itr number of times, do-\n",
    "  * define misclassified array\n",
    "  * for all the feature vectors in dataset,\n",
    "  * append 1 with the feature vector to make its size equal to number of features + 1\n",
    "  * determine the dot product\n",
    "  * if the product is negative and class is omega 1 then delx will -1, insert in misclassified array (delx * feature vector)\n",
    "  * else if the product is prositive or zero and class is omega 2, then delx will be -1, insert in misclassifies array (delx * feature vector)\n",
    "  * if the number of correctly classified is greater than hs then update hs = number of correctly classified, ws = w.\n",
    "  * if the misclassified array is empty then break, training is done\n",
    "  * else update w = w - learning rate * summation(misclassified\n",
    "4. test the model.\n",
    "5. output the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pocket_Perceptron:\n",
    "    def __init__(self):\n",
    "        self.w = np.random.uniform(-1, 1, number_of_features + 1)\n",
    "        self.ws = self.w\n",
    "        self.hs = 0\n",
    "        self.learning_rate = 0.1\n",
    "\n",
    "    def train_model(self):\n",
    "        global dataset, dataset_size, class_names, max_itr\n",
    "\n",
    "        for itr in range(max_itr):\n",
    "            misclassified = []\n",
    "            for i in range(dataset_size):\n",
    "                x = np.array(dataset[i])\n",
    "                x = np.append(x, 1)\n",
    "                actual_class = class_names[i]\n",
    "\n",
    "                prod = np.dot(self.w, x)\n",
    "\n",
    "                if actual_class == 1 and prod < 0:\n",
    "                    misclassified.append(x * -1)\n",
    "                elif actual_class == 2 and prod >= 0:\n",
    "                    misclassified.append(x)\n",
    "\n",
    "            if self.hs < dataset_size - len(misclassified):\n",
    "                self.hs = dataset_size - len(misclassified)\n",
    "                self.ws = self.w\n",
    "\n",
    "            # all got classified\n",
    "            if len(misclassified) == 0:\n",
    "                sys.stdout.write(\"training done at \" + str(itr + 1) + \"th iteration\\n\")\n",
    "                sys.stdout.write(\"w: \" + str(self.ws) + \"\\n\")\n",
    "                break\n",
    "\n",
    "            # update w\n",
    "            summation = sum(misclassified)\n",
    "            self.w = self.w - self.learning_rate * summation\n",
    "\n",
    "    def test_model(self, test_file):\n",
    "        global class_names\n",
    "\n",
    "        correctly_classified = 0\n",
    "        results = open(\"results.txt\", \"w\")\n",
    "        results.write(\"Pocket Algorithm\\n\\n\")\n",
    "\n",
    "        f = open(test_file, \"r\")\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for i in range(len(lines)):\n",
    "            data = list(map(float, lines[i].rstrip().split()))\n",
    "            actual_class = int(data[number_of_features])\n",
    "            data[number_of_features] = 1\n",
    "            data = np.array(data)\n",
    "\n",
    "            prod = np.dot(self.ws, data)\n",
    "\n",
    "            if prod > 0:\n",
    "                predicted_class = 1\n",
    "            else:\n",
    "                predicted_class = 2\n",
    "\n",
    "            if actual_class == predicted_class:\n",
    "                correctly_classified += 1\n",
    "            else:\n",
    "                results.write(\"sample no.: \" + str(i + 1) + \". feature value: \" + str(\n",
    "                    data[:number_of_features]) + \". actual class: \" + str(actual_class) + \". predicted class: \" + str(\n",
    "                    predicted_class) + \"\\n\")\n",
    "\n",
    "        accuracy = (correctly_classified / len(lines)) * 100\n",
    "        sys.stdout.write(\"Correctly classified: \" + str(correctly_classified) + \"\\n\")\n",
    "        sys.stdout.write(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "        results.write(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done at 282th iteration\n",
      "w: [ 168.40547746    3.60597856   -7.85285501 -192.50502771 1755.28252357]\n",
      "Correctly classified: 400\n",
      "Accuracy: 100.0"
     ]
    }
   ],
   "source": [
    "test_file_1 = \"./dataset/testLinearlySeparable.txt\"\n",
    "train_file_1 = \"./dataset/trainLinearlySeparable.txt\"\n",
    "\n",
    "test_file_2 = \"./dataset/testLinearlyNonSeparable.txt\"\n",
    "train_file_2 = \"./dataset/trainLinearlyNonSeparable.txt\"\n",
    "\n",
    "read_dataset(train_file_1)\n",
    "p = Perceptron()\n",
    "p.train_model()\n",
    "p.test_model(test_file_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run pocket algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done at 112th iteration\n",
      "w: [ 73.53643762   3.50470171  -1.1180569  -79.78705474 716.79954562]\n",
      "Correctly classified: 391\n",
      "Accuracy: 97.75"
     ]
    }
   ],
   "source": [
    "test_file_1 = \"./dataset/testLinearlySeparable.txt\"\n",
    "train_file_1 = \"./dataset/trainLinearlySeparable.txt\"\n",
    "\n",
    "test_file_2 = \"./dataset/testLinearlyNonSeparable.txt\"\n",
    "train_file_2 = \"./dataset/trainLinearlyNonSeparable.txt\"\n",
    "\n",
    "read_dataset(train_file_2)\n",
    "p = Pocket_Perceptron()\n",
    "p.train_model()\n",
    "p.test_model(test_file_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run reward and punishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done at 61th iteration\n",
      "w: [ 43.15850211   3.32684961   0.5498498  -44.5739692  383.09160309]\n",
      "Correctly classified: 400\n",
      "Accuracy: 100.0"
     ]
    }
   ],
   "source": [
    "test_file_1 = \"./dataset/testLinearlySeparable.txt\"\n",
    "train_file_1 = \"./dataset/trainLinearlySeparable.txt\"\n",
    "\n",
    "test_file_2 = \"./dataset/testLinearlyNonSeparable.txt\"\n",
    "train_file_2 = \"./dataset/trainLinearlyNonSeparable.txt\"\n",
    "\n",
    "read_dataset(train_file_1)\n",
    "p = Pocket_Perceptron()\n",
    "p.train_model()\n",
    "p.test_model(test_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
